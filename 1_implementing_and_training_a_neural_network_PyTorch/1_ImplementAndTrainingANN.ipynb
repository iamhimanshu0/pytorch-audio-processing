{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeYK3SNl8xXL"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchaudio torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MrYp4xdd89BY"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQckQCyJ9jWV"
      },
      "source": [
        "### 1 .Download Dataset\n",
        "### 2 .Create Data Loader\n",
        "### 3 .Build Model\n",
        "### 4 .Train\n",
        "### 5 .Save Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rEGYC8ND9HAa"
      },
      "outputs": [],
      "source": [
        "# Downlaod data\n",
        "def download_mnist_datasets():\n",
        "  train_data = datasets.MNIST(\n",
        "      root='data',\n",
        "      download = True,\n",
        "      train= True,\n",
        "      transform = ToTensor()\n",
        "  )\n",
        "\n",
        "  validation_data = datasets.MNIST(\n",
        "      root='data',\n",
        "      download = True,\n",
        "      train= False,\n",
        "      transform = ToTensor()\n",
        "  )\n",
        "\n",
        "  return train_data, validation_data\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hEgWALuJ9G8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52916f32-f978-40f4-89e5-ed421fcda1bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded\n"
          ]
        }
      ],
      "source": [
        "# download dataset\n",
        "train_data, _ = download_mnist_datasets()\n",
        "print(\"Dataset downloaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6niuL3We9G4a"
      },
      "outputs": [],
      "source": [
        "# create a dataloader (class used to wrap a dataset\n",
        "                        # it's allows to load data into batches\n",
        "                      #)\n",
        "\n",
        "# for train \n",
        "BATCH_SIZE = 128\n",
        "train_data_loader = DataLoader(train_data,\n",
        "                               batch_size = BATCH_SIZE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "S5tAZ17t9G2D"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "class FeedForwardNet(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dense_layers = nn.Sequential(\n",
        "        nn.Linear(28*28, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 10)\n",
        "    )\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self,input_data):\n",
        "    \n",
        "    flattened_data = self.flatten(input_data)\n",
        "    logits = self.dense_layers(flattened_data)\n",
        "    predictions = self.softmax(logits)\n",
        "    return logits  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poKz0MdTFDTG",
        "outputId": "b8555334-7c4d-4f31-f792-a62937c6acad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "print(f\"using device {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ssWtbWGr9GzX"
      },
      "outputs": [],
      "source": [
        "# build the model\n",
        "feed_forward_net = FeedForwardNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gUmRIU8T9Gvu"
      },
      "outputs": [],
      "source": [
        "# train to model\n",
        "def train_one_epoch(model, data_loader, loss_fn, optimiser, device):\n",
        "  for inputs, targets in data_loader:\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    \n",
        "    # calculate loss\n",
        "    predictions = model(inputs)\n",
        "    loss = loss_fn(predictions, targets)\n",
        "\n",
        "    # backpropagate loss and update weights\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "  \n",
        "  print(f\"Loss : {loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OwOJpP2x9GtL"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
        "  for i in range(epochs):\n",
        "    print(f\"Epoch {i+1}\")\n",
        "    train_one_epoch(model, data_loader, loss_fn, optimiser, device)\n",
        "    print(\"---------------------------\")\n",
        "  \n",
        "  print(\"Training is Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "U4KrFZjdIy52"
      },
      "outputs": [],
      "source": [
        "# loss fun + optimizer\n",
        "LEARNING_RATE = .001\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(\n",
        "    feed_forward_net.parameters(),\n",
        "    lr=LEARNING_RATE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2jHUVJK9Gqm",
        "outputId": "6ace6433-4860-484d-d2a8-ef8e0b6f81b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Loss : 0.2699134349822998\n",
            "---------------------------\n",
            "Epoch 2\n",
            "Loss : 0.21806180477142334\n",
            "---------------------------\n",
            "Epoch 3\n",
            "Loss : 0.18600553274154663\n",
            "---------------------------\n",
            "Epoch 4\n",
            "Loss : 0.16591830551624298\n",
            "---------------------------\n",
            "Epoch 5\n",
            "Loss : 0.1489981859922409\n",
            "---------------------------\n",
            "Epoch 6\n",
            "Loss : 0.12755537033081055\n",
            "---------------------------\n",
            "Epoch 7\n",
            "Loss : 0.11052163690328598\n",
            "---------------------------\n",
            "Epoch 8\n",
            "Loss : 0.09465482085943222\n",
            "---------------------------\n",
            "Epoch 9\n",
            "Loss : 0.07964987307786942\n",
            "---------------------------\n",
            "Epoch 10\n",
            "Loss : 0.05756214261054993\n",
            "---------------------------\n",
            "Training is Done!\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "EPOCHS = 10\n",
        "train(feed_forward_net, train_data_loader, loss_fn, optimiser, device, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaQhN7Lk9GoH",
        "outputId": "895cae6d-d9b7-4412-e6af-9c78dcaacacd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "# save the model\n",
        "torch.save(feed_forward_net.state_dict(), \n",
        "           \"feedforwardnet.pth\")\n",
        "print(\"Model saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading model and making infrences"
      ],
      "metadata": {
        "id": "zXRlMWB6PZb4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "zQE8iNSi9Gkw"
      },
      "outputs": [],
      "source": [
        "# load back model\n",
        "# load MNIST validation dataset\n",
        "# get a sample from the validation dataset for inferecee\n",
        "# make a inferece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "04fb5rxl9GiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a2416d-018a-45c2-d97c-b19befd839e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# load the model\n",
        "feed_forword_net = FeedForwardNet()\n",
        "state_dict = torch.load(\"/content/feedforwardnet.pth\")\n",
        "\n",
        "feed_forward_net.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "yJoVc6tD9GfS"
      },
      "outputs": [],
      "source": [
        "# loading MNIST dataset validate\n",
        "_, validation_data = download_mnist_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a sample from the validation dataset for inferecee\n",
        "input, target = validation_data[0][0],validation_data[0][1]  # first sample, target"
      ],
      "metadata": {
        "id": "sdtli0ItQXbH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = [\n",
        "                \"0\",\n",
        "                \"1\",\n",
        "                \"2\",\n",
        "                \"3\",\n",
        "                \"4\",\n",
        "                \"5\",\n",
        "                \"6\",\n",
        "                \"7\",\n",
        "                \"8\",\n",
        "                \"9\"\n",
        "                ]"
      ],
      "metadata": {
        "id": "j9yfV_rJRSfO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,input, target, class_mapping):\n",
        "  model.eval() # evulation\n",
        "  with torch.no_grad():\n",
        "    predictions = model(input.to(device))\n",
        "    # Tensor object  (1, 10) -> [[0.1,0.01....0.6]]\n",
        "    predicted_index = predictions[0].argmax(0)\n",
        "    predicted = class_mapping[predicted_index]\n",
        "    expected = class_mapping[target]\n",
        "\n",
        "    return predicted, expected"
      ],
      "metadata": {
        "id": "G6kkng9JRoGB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make an infereces\n",
        "predicted, expected = predict(feed_forward_net,input, target,class_mapping)\n",
        "\n",
        "print(f\"Predicted: {predicted} , expected: {expected}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhCVn7-LQ0N2",
        "outputId": "c6a1f97a-68b8-41df-c044-ee2d9e978fb9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 7 , expected: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wYMmGTDwTFlq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1_ImplementAndTrainingANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}